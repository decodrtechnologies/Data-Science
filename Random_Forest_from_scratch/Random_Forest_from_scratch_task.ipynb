{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.*\n",
    "\n",
    "One big advantage of random forest is that it can be used for both **classification** and **regression problems**, which form the majority of current machine learning systems.\n",
    "\n",
    "Random forest adds additional randomness to the model, while growing the trees. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model.\n",
    "\n",
    "Therefore, in random forest, only a random subset of the features is taken into consideration by the algorithm for splitting a node. You can even make trees more random by additionally using random thresholds for each feature rather than searching for the best possible thresholds (like a normal decision tree does).\n",
    "\n",
    "**WHY RANDOM FOREST ?**\n",
    "- The same random forest algorithm or the random forest classifier can use for both classification and the regression task.\n",
    "- Random forest classifier will handle the missing values.\n",
    "- When we have more trees in the forest, random forest classifier won’t overfit the model.\n",
    "- Can model the random forest classifier for categorical values also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE : IMPLEMENT RANDOM FOREST FROM SCRATCH \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREREQUISITE : \n",
    "\n",
    "DECISION TREE ALGORITHM\n",
    "\n",
    "- Refer the Code present in the [Decision_tree_functions]() to know the implementation of Decision tree.\n",
    "- Our focus in this Notebook is to implement Random forest using the knowledge of Decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA\n",
    "We will be using a [Red Wine quality](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) from the Kaggle platform which has a very good collection of datasets.\n",
    "  \n",
    "The data is presented in CSV format.\n",
    "\n",
    "Features:\n",
    "- fixed acidity\n",
    "- volatile acidity\n",
    "- citric acid\n",
    "- residual sugar\n",
    "- chlorides\n",
    "- free sulfur dioxide\n",
    "- total sulfur dioxide\n",
    "- densitythe density \n",
    "- pHdescribes\n",
    "- sulphatesa wine \n",
    "- alcohol\n",
    "- quality (OUTPUT VARIABLE)\n",
    "  \n",
    "Note that prices have been adjusted for dividends and splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import all the libraries required to complete the task\"\"\"\n",
    "\n",
    "\"\"\"import the below functions from decision_tree_functions.py file\n",
    "   - decision_tree_algorithm\n",
    "   - decision_tree_predictions\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Format of the data*\n",
    "- the last column of the data frame must contain the label and it must also be called \"label\"\n",
    "- there should be no missing values in the data frame\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading the CSV file using pandas that contains the data and consider **quality** as the output variable\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Replace the space in feature names with the '_' underscore\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" display the top 5 data instances\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" normalise the label and sort according to the index and plot \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Write a function to covert the label into binary classes \n",
    "    value below 5 is bad and above is good \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" normalise the label and plot bar graph\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed function is used to save the state of random function, \n",
    "    so that it can generate some random numbers on multiple execution of the code on the same machine or\n",
    "    on different machines (for a specific seed value). Seed value is the previous value number generated by the generator.\n",
    "    For the first time when there is no previous value, it uses current system time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"initiaise a random function using seedfunction\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  write a function to split the Data \"\"\"\n",
    "# 1. Train-Test-Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Write a function to create a bootstrap dataset with parameters as dataset and size of bootstrap dataset required\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest pseudocode:**\n",
    "- Randomly select “k” features from total “m” features.\n",
    "  Where k << m\n",
    "- Among the “k” features, calculate the node “d” using the best split point.\n",
    "- Split the node into daughter nodes using the best split.\n",
    "- Repeat 1 to 3 steps until “l” number of nodes has been reached.\n",
    "- Build forest by repeating steps 1 to 4 for “n” number times to create “n” number of trees.\n",
    "- The beginning of random forest algorithm starts with randomly selecting “k” features out of total “m” features. In the image, you can observe that we are randomly taking features and observations.\n",
    "- In the next stage, we are using the randomly selected “k” features to find the root node by using the best split approach.\n",
    "- The next stage, We will be calculating the daughter nodes using the same best split approach. Will the first 3 stages until we form the tree with a root node and having the target as the leaf node.\n",
    "- Finally, we repeat 1 to 4 stages to create “n” randomly created trees. This randomly created trees forms the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Write a function to create a Random forest using decision tree function importes\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest prediction pseudocode:\n",
    "- To perform prediction using the trained random forest algorithm uses the below pseudocode.\n",
    "- Takes the test features and use the rules of each randomly created decision tree to predict the oucome and stores the predicted outcome (target)\n",
    "- Calculate the votes for each predicted target.\n",
    "- Consider the high voted predicted target as the final prediction from the random forest algorithm.\n",
    "- To perform the prediction using the trained random forest algorithm we need to pass the test features through the rules of each randomly created trees. Suppose let’s say we formed 100 random decision trees to from the random forest.\n",
    "- Each random forest will predict different target (outcome) for the same test feature. Then by considering each predicted target votes will be calculated. Suppose the 100 random decision trees are prediction some 3 unique targets x, y, z then the votes of x is nothing but out of 100 random decision tree how many trees prediction is x.\n",
    "- Likewise for other 2 targets (y, z). If x is getting high votes. Let’s say out of 100 random decision tree 60 trees are predicting the target will be x. Then the final random forest returns the x as the predicted target.\n",
    "- This concept of voting is known as **majority voting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write the function to predict using random forest trees\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write a function to calculate accuracy where accuracy is mean of correct predictions\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" call the random forest function  \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" call the prediction function\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" calculate the accuracy\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
